{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfc25e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N links: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse\n",
    "\n",
    "BASE = \"https://nexoinmobiliario.pe\"\n",
    "\n",
    "PROJECT_RE = re.compile(r\"^/proyecto/venta-de-departamento-\\d+-\")\n",
    "\n",
    "def fetch_html(url: str, timeout=30) -> str:\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \"\n",
    "                      \"(KHTML, like Gecko) Chrome/120.0 Safari/537.36\"\n",
    "    }\n",
    "    r = requests.get(url, headers=headers, timeout=timeout)\n",
    "    r.raise_for_status()\n",
    "    return r.text\n",
    "\n",
    "def extract_project_links_from_inmobiliaria(html: str):\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # 1) apunta al contenedor grande (tu class)\n",
    "    container = soup.select_one(\"div.SearchResult-projects.scrollNormal\") or soup\n",
    "\n",
    "    links = set()\n",
    "    # 2) dentro de cada card, el link al proyecto suele estar en el h2 > a\n",
    "    for a in container.select(\"div.SearchResult-project-data h2 a[href]\"):\n",
    "        href = a[\"href\"].strip()\n",
    "        if href.startswith(\"/\"):\n",
    "            # Nexo está usando /proyecto/... en esta vista (según tu screenshot)\n",
    "            if PROJECT_RE.match(href):\n",
    "                links.add(urljoin(BASE, href))\n",
    "        else:\n",
    "            if \"nexoinmobiliario.pe/proyecto/\" in href:\n",
    "                links.add(href)\n",
    "\n",
    "    # fallback: por si cambia el HTML, agarramos cualquier /proyecto/ dentro del contenedor\n",
    "    if not links:\n",
    "        for a in container.select(\"a[href]\"):\n",
    "            href = a[\"href\"].strip()\n",
    "            if href.startswith(\"/proyecto/\"):\n",
    "                links.add(urljoin(BASE, href))\n",
    "\n",
    "    return sorted(links)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = \"https://nexoinmobiliario.pe/inmobiliarias/edifica\"\n",
    "    html = fetch_html(url)\n",
    "    project_urls = extract_project_links_from_inmobiliaria(html)\n",
    "    print(\"N links:\", len(project_urls))\n",
    "    print(\"\\n\".join(project_urls[:10]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da9ca67",
   "metadata": {},
   "source": [
    "# ver otros proyectos dentro de 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdf86483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/3] Fetch: https://nexoinmobiliario.pe/departamentos/barranco/grau-10-3809\n",
      "  -> encontrados: 17\n",
      "[2/3] Fetch: https://nexoinmobiliario.pe/proyecto/venta-de-departamento-3209-tulipan-cercado-de-lima-lima-lima-abril-grupo-inmobiliario\n",
      "  -> encontrados: 16\n",
      "[3/3] Fetch: https://nexoinmobiliario.pe/proyecto/venta-de-departamento-2308-smart-a-santa-beatriz-cercado-de-lima-lima-lima-grupo-mg\n",
      "  -> encontrados: 21\n",
      "\n",
      "OK. filas: 54 -> otros_proyectos.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse\n",
    "\n",
    "BASE = \"https://nexoinmobiliario.pe\"\n",
    "ID_RE_END = re.compile(r\"-(\\d+)$\")\n",
    "\n",
    "DEFAULT_HEADERS = {\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0 Safari/537.36\"\n",
    "    ),\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "}\n",
    "\n",
    "def fetch_html(url: str, timeout=30) -> str:\n",
    "    r = requests.get(url, headers=DEFAULT_HEADERS, timeout=timeout)\n",
    "    r.raise_for_status()\n",
    "    return r.text\n",
    "\n",
    "def extract_otros_links(html: str, base_url: str = BASE):\n",
    "    \"\"\"\n",
    "    Extrae links de 'Otros Departamentos / Otros proyectos' desde el carrusel:\n",
    "    - a.carousel-extra-section-otros-btn[href] (ideal)\n",
    "    - div.carousel-extra-section-otros-share[data-url] (fallback)\n",
    "    Devuelve lista de dicts.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # La sección suele contener: section-final-departamentos-inmobiliaria-otros2\n",
    "    # Pero para hacerlo robusto: buscamos cualquier card de 'carousel-extra-section-otros-card'\n",
    "    cards = soup.select(\"div.carousel-extra-section-otros-card\")\n",
    "\n",
    "    items = []\n",
    "    for card in cards:\n",
    "        # Link principal (botón Ver proyecto)\n",
    "        a = card.select_one(\"a.carousel-extra-section-otros-btn[href]\")\n",
    "        href = a[\"href\"].strip() if a and a.has_attr(\"href\") else None\n",
    "        url = urljoin(base_url, href) if href else None\n",
    "\n",
    "        # Fallback: data-url en el share\n",
    "        if not url:\n",
    "            share = card.select_one(\"div.carousel-extra-section-otros-share[data-url]\")\n",
    "            if share and share.has_attr(\"data-url\"):\n",
    "                url = share[\"data-url\"].strip()\n",
    "\n",
    "        if not url:\n",
    "            continue\n",
    "\n",
    "        title_el = card.select_one(\"h3.carousel-extra-section-otros-title\")\n",
    "        price_el = card.select_one(\"div.carousel-extra-section-otros-price\")\n",
    "        badge_el = card.select_one(\"div.carousel-extra-section-otros-badge\")\n",
    "\n",
    "        title = title_el.get_text(strip=True) if title_el else None\n",
    "        price_text = price_el.get_text(\" \", strip=True) if price_el else None\n",
    "        badge = badge_el.get_text(\" \", strip=True) if badge_el else None\n",
    "\n",
    "        project_id = None\n",
    "        m = ID_RE_END.search(urlparse(url).path)\n",
    "        if m:\n",
    "            project_id = m.group(1)\n",
    "\n",
    "        items.append(\n",
    "            {\n",
    "                \"url\": url,\n",
    "                \"project_id\": project_id,\n",
    "                \"title\": title,\n",
    "                \"price_text\": price_text,\n",
    "                \"badge\": badge,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # dedupe por url (manteniendo orden)\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for it in items:\n",
    "        if it[\"url\"] not in seen:\n",
    "            seen.add(it[\"url\"])\n",
    "            out.append(it)\n",
    "    return out\n",
    "\n",
    "def run(urls, sleep_s=1.0, out_csv=\"otros_proyectos.csv\"):\n",
    "    rows = []\n",
    "    for i, seed_url in enumerate(urls, start=1):\n",
    "        print(f\"[{i}/{len(urls)}] Fetch: {seed_url}\")\n",
    "        try:\n",
    "            html = fetch_html(seed_url)\n",
    "            otros = extract_otros_links(html, base_url=BASE)\n",
    "\n",
    "            print(f\"  -> encontrados: {len(otros)}\")\n",
    "            for it in otros:\n",
    "                rows.append(\n",
    "                    {\n",
    "                        \"seed_url\": seed_url,\n",
    "                        \"other_url\": it[\"url\"],\n",
    "                        \"other_project_id\": it[\"project_id\"],\n",
    "                        \"other_title\": it[\"title\"],\n",
    "                        \"other_price_text\": it[\"price_text\"],\n",
    "                        \"other_badge\": it[\"badge\"],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  !! error: {e}\")\n",
    "\n",
    "        time.sleep(sleep_s)\n",
    "\n",
    "    # export CSV\n",
    "    if rows:\n",
    "        fieldnames = list(rows[0].keys())\n",
    "        with open(out_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            w = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "            w.writeheader()\n",
    "            w.writerows(rows)\n",
    "\n",
    "    print(f\"\\nOK. filas: {len(rows)} -> {out_csv}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    URLS = [\n",
    "        \"https://nexoinmobiliario.pe/departamentos/barranco/grau-10-3809\",\n",
    "        \"https://nexoinmobiliario.pe/proyecto/venta-de-departamento-3209-tulipan-cercado-de-lima-lima-lima-abril-grupo-inmobiliario\",\n",
    "        \"https://nexoinmobiliario.pe/proyecto/venta-de-departamento-2308-smart-a-santa-beatriz-cercado-de-lima-lima-lima-grupo-mg\",\n",
    "        # agrega aquí tus otras 2…\n",
    "    ]\n",
    "    run(URLS, sleep_s=1.2, out_csv=\"otros_proyectos.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0737aec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import re\n",
    "\n",
    "BASE = \"https://nexoinmobiliario.pe\"\n",
    "\n",
    "def extract_otros_proyectos(html: str):\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # Sección: \"Otros Departamentos en ...\"\n",
    "    section = soup.select_one(\"div.section-final-departamentos-inmobiliaria-otros2\")\n",
    "    if not section:\n",
    "        return []\n",
    "\n",
    "    items = []\n",
    "    for card in section.select(\"div.carousel-extra-section-otros-card\"):\n",
    "        # 1) Link principal (botón \"Ver proyecto\")\n",
    "        a = card.select_one(\"a.carousel-extra-section-otros-btn[href]\")\n",
    "        href = a[\"href\"].strip() if a and a.has_attr(\"href\") else None\n",
    "        url = urljoin(BASE, href) if href else None\n",
    "\n",
    "        # 2) Fallback: data-url del share\n",
    "        if not url:\n",
    "            share = card.select_one(\"div.carousel-extra-section-otros-share[data-url]\")\n",
    "            if share and share.has_attr(\"data-url\"):\n",
    "                url = share[\"data-url\"].strip()\n",
    "\n",
    "        title_el = card.select_one(\"h3.carousel-extra-section-otros-title\")\n",
    "        price_el = card.select_one(\"div.carousel-extra-section-otros-price\")\n",
    "        badge_el = card.select_one(\"div.carousel-extra-section-otros-badge\")\n",
    "\n",
    "        title = title_el.get_text(strip=True) if title_el else None\n",
    "        price = price_el.get_text(\" \", strip=True) if price_el else None\n",
    "        badge = badge_el.get_text(\" \", strip=True) if badge_el else None\n",
    "\n",
    "        # opcional: sacar id del final (…-3530)\n",
    "        project_id = None\n",
    "        if url:\n",
    "            m = re.search(r\"-(\\d+)$\", url)\n",
    "            project_id = m.group(1) if m else None\n",
    "\n",
    "        if url:\n",
    "            items.append({\n",
    "                \"url\": url,\n",
    "                \"project_id\": project_id,\n",
    "                \"title\": title,\n",
    "                \"price_text\": price,\n",
    "                \"badge\": badge,\n",
    "            })\n",
    "\n",
    "    # dedupe por url\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for it in items:\n",
    "        if it[\"url\"] not in seen:\n",
    "            seen.add(it[\"url\"])\n",
    "            out.append(it)\n",
    "    return out\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
